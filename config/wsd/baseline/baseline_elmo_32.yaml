meta_learner: baseline
meta_model: seq
learner_model: mlp
learner_params:
  hidden_size: 256
  num_outputs:
    wsd: 5612
  embed_dim: 1024
  dropout_ratio: 0
vectors: elmo
output_lr: 0.1
learner_lr: 0.001
num_shots:
  wsd: 32
num_updates: 7
num_test_samples:
  wsd: 32
num_train_episodes:
  wsd: 10000
num_val_episodes:
  wsd: 84
num_test_episodes:
  wsd: 129
num_meta_epochs: 25
early_stopping: 2
device: cuda:0
proto_maml: false
