meta_learner: baseline
meta_model: seq_meta_model
learner_params:
  hidden_size: 128
  num_outputs:
    pos: 17
    wsd: 8229
    metaphor: 2
  embed_dim: 1024
learner_lr: 0.01
num_shots:
  pos: 64
  wsd: 64
  metaphor: 64
num_updates: 1
num_test_samples:
  pos: 1024
  wsd: 1024
  metaphor: 1024
num_episodes:
  pos: 1
  wsd: 1
  metaphor: 1
num_meta_epochs: 20
early_stopping: 10
proto_maml: false
