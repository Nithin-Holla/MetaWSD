meta_learner: baseline
meta_model: seq_meta_model
learner_params:
  hidden_size: 128
  num_outputs:
    pos: 17
    wsd: 44600
    metaphor: 1
  embed_dim: 1024
learner_lr: 0.001
num_shots:
  pos: 64
  wsd: 64
  metaphor: 64
num_updates: 1
num_test_samples:
  pos: 64
  wsd: 64
  metaphor: all
num_episodes:
  pos: 5
  wsd: 5
  metaphor: 1
num_meta_epochs: 50
early_stopping: 5
device: cuda:0
proto_maml: false
